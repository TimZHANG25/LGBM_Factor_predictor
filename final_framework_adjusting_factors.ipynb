{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# from flaml import tune\n",
    "from matplotlib import rcParams\n",
    "from function2 import *\n",
    "import glob\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pymssql\n",
    "import os\n",
    "import joblib\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# from flaml import AutoML\n",
    "# from flaml.default import LGBMRegressor\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "# rcParams['font.family'] = 'SimHei'\n",
    "from sql_server_token import PASSWORD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基础参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''训练模型'''\n",
    "# 注：下文中，测试集指一般意义上的验证集，验证集指一般意义下的测试集\n",
    "time_unit = '月'   # 数据长度单位\n",
    "unit = '周'   # 收益频率\n",
    "n_train = 36    #训练集长度\n",
    "response_type = '收益率' #可以选择收益率，夏普率，收益率分类，夏普率分类作为标签，目前使用收益率；若使用分类标签，后续训练过程有参数需要改变\n",
    "rolling_window = 1  # rolling_window一般不需改动\n",
    "# rolling_unit = '月' # 可选年/月/周\n",
    "get_date_unit = '年' # get_date的间隔参数 测试集长度\n",
    "get_date_unit_validation = '月' # validation_set的参数 可选年/月/half(half year)\n",
    "\n",
    "initial_year = 2019 # 回测起始年\n",
    "final_year = 2021 #回测结束年\n",
    "data_local = False # 数据是否已存本地 第一次运行需要False，后续改为True\n",
    "data_in_all = True #股票池是否来自全市场\n",
    "OutputPath_result = 'model_output_all' # 最终结果的存储路径\n",
    "result_excel = 'output_3_year_train_total.xlsx' # 最终结果的文件名\n",
    "y_predict_name = 'y_by_year_all.pkl' # 因子预测值储存文件名\n",
    "validation_set = 1\n",
    "rolling_style = 1\n",
    "orthogonalization = True #是否正交化\n",
    "factor_to_zero = False #是否将部分因子值设为0\n",
    "\n",
    "\n",
    "\n",
    "# shutil.rmtree('model_regression_500_best_' + str(int((n_train)/12))+'year_train_by_month')\n",
    "# os.mkdir('model_regression_500_best_' + str(int((n_train)/12))+'year_train_by_month')\n",
    "\n",
    "\n",
    "# param_grid = {\n",
    "#    'max_depth':  [3,4,5],\n",
    "#    'learning_rate': [0.05,0.1,0.2],\n",
    "#    'n_estimators': [100,200,300,400,500,600]\n",
    "# }\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth':  [3],\n",
    "    'learning_rate': [0.01],\n",
    "    'n_estimators': [100]\n",
    "}\n",
    "\n",
    "\n",
    "file_names = sorted(glob.glob(r'C:\\Users\\24343\\Desktop\\实习\\国泰君安量化组\\数据库\\因子数据\\因子中性化数据1130\\*'))   # 加载文件名称\n",
    "# file_names = sorted(glob.glob(r'C:\\bak\\新增資料夾\\lgb因子\\因子标准化数据1130.part01\\因子标准化数据1130\\*'))   # 加载文件名称\n",
    "\n",
    "# dates是全程日期，dates_train是测试集取值的范围\n",
    "dates_train = [datetime(year, 1, 1).strftime('%Y-%m-%d') for year in range(initial_year, final_year + 1)]\n",
    "\n",
    "server = '(local)'\n",
    "database = 'winddb0102'\n",
    "username = 'sa'\n",
    "\n",
    "# conn = pymssql.connect('(local)', 'sa', '123456', 'winddb0102')  # 连接sql server\n",
    "conn = pyodbc.connect(f'DRIVER={{SQL Server}};'\n",
    "                      f'SERVER={server};'\n",
    "                      f'DATABASE={database};'\n",
    "                      f'UID={username};'\n",
    "                      f'PWD={PASSWORD}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 先获取总交易日，然后取出月/周来训练: 先取三年，然后取一个月/周回测，测完加入训练集，再删一个月/周，训练集长度保持不变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRADE_DT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20190102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20190103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20190104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20190107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20190108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>20211227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>20211228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>20211229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>20211230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>20211231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>730 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TRADE_DT\n",
       "0    20190102\n",
       "1    20190103\n",
       "2    20190104\n",
       "3    20190107\n",
       "4    20190108\n",
       "..        ...\n",
       "725  20211227\n",
       "726  20211228\n",
       "727  20211229\n",
       "728  20211230\n",
       "729  20211231\n",
       "\n",
       "[730 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 总交易日：\n",
    "Calender_all = Load_Calender(file_names, dates_train[0], 12*len(dates_train), time_unit, '日')\n",
    "Calender_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 再获取周度调仓日"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRADE_DT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>2023-12-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>2023-12-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>2024-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2024-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2024-01-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TRADE_DT\n",
       "0   2019-01-02\n",
       "1   2019-01-09\n",
       "2   2019-01-16\n",
       "3   2019-01-23\n",
       "4   2019-01-30\n",
       "..         ...\n",
       "241 2023-12-19\n",
       "242 2023-12-26\n",
       "243 2024-01-03\n",
       "244 2024-01-10\n",
       "245 2024-01-17\n",
       "\n",
       "[246 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调仓日\n",
    "Calender_change = get_trade_date(file_names, dates_train[0], '周')\n",
    "Calender_change['TRADE_DT'] = pd.to_datetime(Calender_change['TRADE_DT'], format='%Y%m%d')\n",
    "Calender_change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 具体函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_factors_to_zero(data):\n",
    "    \"\"\"\n",
    "    处理数据集中的因子\n",
    "    \n",
    "    参数：\n",
    "    - data: 包含时间、股票名称、因子和收益率的DataFrame\n",
    "    \n",
    "    返回值：\n",
    "    - 更新后的data，其中因子列被替换为处理后的因子数据\n",
    "    \"\"\"\n",
    "    # 提取因子数据（剔除前两列和最后一列）\n",
    "    factor_data = data.iloc[:, 2:-1]\n",
    "\n",
    "    # 计算因子中位数\n",
    "    factor_medians = factor_data.median()\n",
    "\n",
    "    # 使用NumPy进行向量化运算，将小于中位数的值设置为空\n",
    "    processed_factor_data = np.where(factor_data.values < factor_medians.values, 0, factor_data.values)\n",
    "\n",
    "    # 将原始data中的因子数据更新为处理后的因子数据\n",
    "    data.iloc[:, 2:-1] = processed_factor_data\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def normalization(data):\n",
    "    # 提取因子数据（剔除前两列和最后一列）\n",
    "    factor_data = data.iloc[:, 2:-1]\n",
    "    \n",
    "    # 对因子数据进行横截面z-score归一化\n",
    "    normalized_factors = (factor_data - factor_data.mean()) / factor_data.std()\n",
    "    data.iloc[:, 2:-1] = normalized_factors\n",
    "    # data = data.dropna(axis=0, how='any').reset_index(drop=True) #需无空列\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def orthogonalize_factors(data): #无空列\n",
    "    \"\"\"\n",
    "    将训练集中的因子进行对称正交\n",
    "    \n",
    "    参数：\n",
    "    - data: 包含时间、股票名称、因子和收益率的DataFrame\n",
    "    \n",
    "    返回值：\n",
    "    - 更新后的data，其中因子列被替换为对称正交后的因子数据\n",
    "    \"\"\"\n",
    "    data = normalization(data)\n",
    "    normalized_factors = data.iloc[:, 2:-1]\n",
    "\n",
    "    # 计算特征值和特征向量\n",
    "    D, U = np.linalg.eig(np.dot(normalized_factors.T, normalized_factors))\n",
    "\n",
    "    D = np.abs(D) #取绝对值防止报错\n",
    "    U = np.mat(U)\n",
    "    d = np.diag(D**(-0.5))\n",
    "    S = (U*d*U.T).real #取实部防止报错\n",
    "    F_hat = np.mat(normalized_factors)*S \n",
    "    \n",
    "    # 将data中的因子数据更新为正交后的因子数据\n",
    "    data.iloc[:, 2:-1] = F_hat\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def orthogonalize_factors_with_nan(data):\n",
    "    \"\"\"\n",
    "    根据输入数据的因子情况，进行对称正交\n",
    "    \n",
    "    参数：\n",
    "    - data: 包含时间、股票名称、因子和收益率的DataFrame\n",
    "    \n",
    "    返回值：\n",
    "    - 更新后的data，其中因子列被替换为对称正交后的因子数据\n",
    "    \"\"\"\n",
    "\n",
    "    # 检查是否存在空列\n",
    "    if (data == 0).all().any():\n",
    "        # 存在空列，记下空列的位置和字段\n",
    "        zero_columns = data.columns[(data == 0).all()].tolist()\n",
    "        # 删除空列\n",
    "        result_data = data.drop(zero_columns, axis=1)\n",
    "\n",
    "        \n",
    "        # 进行正交处理\n",
    "        result_data = orthogonalize_factors(result_data)\n",
    "\n",
    "        # 在原来空列的位置上添加空列\n",
    "        for col in zero_columns:\n",
    "            # 获取原空列的位置\n",
    "            col_position = data.columns.get_loc(col)\n",
    "            # 在原位置上插入空列\n",
    "            result_data.insert(col_position, col, np.nan)\n",
    "\n",
    "    else:\n",
    "        # 不存在空列，直接使用正交函数更新数据\n",
    "        result_data = orthogonalize_factors(data)\n",
    "\n",
    "    return result_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据...: 100%|██████████| 731/731 [05:44<00:00,  2.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRADE_DT</th>\n",
       "      <th>S_INFO_WINDCODE</th>\n",
       "      <th>Amount_20D_AVG</th>\n",
       "      <th>Amt2RealizedVolatility_5D</th>\n",
       "      <th>BP</th>\n",
       "      <th>CFP_ttm</th>\n",
       "      <th>CashDividendPayoutRatio</th>\n",
       "      <th>EBIT2EV</th>\n",
       "      <th>EPFY3</th>\n",
       "      <th>EP_ded_qfa</th>\n",
       "      <th>...</th>\n",
       "      <th>or_fy3_tb_120d</th>\n",
       "      <th>rank_pbroe_qfa</th>\n",
       "      <th>rank_peg_qfa2</th>\n",
       "      <th>rounte_mom</th>\n",
       "      <th>rtd</th>\n",
       "      <th>turnover1m</th>\n",
       "      <th>turnover3m</th>\n",
       "      <th>turnover_std_3m</th>\n",
       "      <th>varTradeVolume5_10</th>\n",
       "      <th>zdf5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>000006.SZ</td>\n",
       "      <td>0.016521</td>\n",
       "      <td>-0.001878</td>\n",
       "      <td>-0.013350</td>\n",
       "      <td>-0.050224</td>\n",
       "      <td>0.039797</td>\n",
       "      <td>0.023656</td>\n",
       "      <td>-0.009673</td>\n",
       "      <td>-0.013850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>-0.023689</td>\n",
       "      <td>-0.014387</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.006687</td>\n",
       "      <td>-0.005394</td>\n",
       "      <td>-0.007455</td>\n",
       "      <td>-0.044167</td>\n",
       "      <td>-0.186898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>000012.SZ</td>\n",
       "      <td>0.018360</td>\n",
       "      <td>0.045949</td>\n",
       "      <td>-0.010283</td>\n",
       "      <td>0.008461</td>\n",
       "      <td>0.041792</td>\n",
       "      <td>-0.013154</td>\n",
       "      <td>-0.004473</td>\n",
       "      <td>-0.025269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018467</td>\n",
       "      <td>0.023287</td>\n",
       "      <td>0.032429</td>\n",
       "      <td>0.063063</td>\n",
       "      <td>-0.011320</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>-0.017234</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>-0.011703</td>\n",
       "      <td>-0.179700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>000021.SZ</td>\n",
       "      <td>0.007604</td>\n",
       "      <td>-0.009174</td>\n",
       "      <td>0.001322</td>\n",
       "      <td>-0.028544</td>\n",
       "      <td>-0.000120</td>\n",
       "      <td>-0.010430</td>\n",
       "      <td>-0.006332</td>\n",
       "      <td>0.025829</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001388</td>\n",
       "      <td>0.007405</td>\n",
       "      <td>-0.025029</td>\n",
       "      <td>-0.010256</td>\n",
       "      <td>0.013120</td>\n",
       "      <td>-0.008876</td>\n",
       "      <td>-0.008485</td>\n",
       "      <td>-0.015728</td>\n",
       "      <td>0.008078</td>\n",
       "      <td>-0.214747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>000028.SZ</td>\n",
       "      <td>-0.017967</td>\n",
       "      <td>-0.012962</td>\n",
       "      <td>-0.019874</td>\n",
       "      <td>-0.012101</td>\n",
       "      <td>-0.021628</td>\n",
       "      <td>0.006216</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>0.012944</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009309</td>\n",
       "      <td>0.013404</td>\n",
       "      <td>0.011113</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>-0.003714</td>\n",
       "      <td>0.024293</td>\n",
       "      <td>-0.024580</td>\n",
       "      <td>-0.012023</td>\n",
       "      <td>0.002113</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>000030.SZ</td>\n",
       "      <td>-0.025294</td>\n",
       "      <td>-0.003740</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.003205</td>\n",
       "      <td>0.024752</td>\n",
       "      <td>0.005555</td>\n",
       "      <td>-0.012210</td>\n",
       "      <td>0.011224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>0.025218</td>\n",
       "      <td>0.011325</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>0.037349</td>\n",
       "      <td>-0.001005</td>\n",
       "      <td>-0.009503</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>-0.013646</td>\n",
       "      <td>-0.172638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365486</th>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>603877.SH</td>\n",
       "      <td>-0.031773</td>\n",
       "      <td>-0.003502</td>\n",
       "      <td>-0.006375</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>0.027758</td>\n",
       "      <td>0.005939</td>\n",
       "      <td>-0.001940</td>\n",
       "      <td>-0.004896</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001255</td>\n",
       "      <td>-0.000130</td>\n",
       "      <td>-0.001532</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>-0.014368</td>\n",
       "      <td>-0.018003</td>\n",
       "      <td>-0.003988</td>\n",
       "      <td>-0.020923</td>\n",
       "      <td>-0.014804</td>\n",
       "      <td>-0.020224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365487</th>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>603883.SH</td>\n",
       "      <td>-0.015326</td>\n",
       "      <td>0.027342</td>\n",
       "      <td>-0.007114</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.019745</td>\n",
       "      <td>-0.008971</td>\n",
       "      <td>-0.011490</td>\n",
       "      <td>-0.003990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>-0.003639</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>-0.006579</td>\n",
       "      <td>0.011113</td>\n",
       "      <td>-0.012099</td>\n",
       "      <td>-0.007568</td>\n",
       "      <td>-0.005972</td>\n",
       "      <td>-0.039398</td>\n",
       "      <td>-0.036857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365488</th>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>603885.SH</td>\n",
       "      <td>-0.015847</td>\n",
       "      <td>0.029671</td>\n",
       "      <td>-0.005167</td>\n",
       "      <td>0.003013</td>\n",
       "      <td>-0.003062</td>\n",
       "      <td>-0.001466</td>\n",
       "      <td>0.002157</td>\n",
       "      <td>0.006290</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026506</td>\n",
       "      <td>-0.021470</td>\n",
       "      <td>-0.014746</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.013272</td>\n",
       "      <td>-0.010397</td>\n",
       "      <td>-0.010026</td>\n",
       "      <td>-0.005418</td>\n",
       "      <td>0.012436</td>\n",
       "      <td>-0.032721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365489</th>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>603888.SH</td>\n",
       "      <td>-0.007538</td>\n",
       "      <td>0.006159</td>\n",
       "      <td>-0.016373</td>\n",
       "      <td>-0.001432</td>\n",
       "      <td>0.007393</td>\n",
       "      <td>-0.009854</td>\n",
       "      <td>0.001899</td>\n",
       "      <td>-0.012305</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001168</td>\n",
       "      <td>-0.002947</td>\n",
       "      <td>-0.008553</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>-0.001674</td>\n",
       "      <td>0.002796</td>\n",
       "      <td>0.002225</td>\n",
       "      <td>-0.005413</td>\n",
       "      <td>0.003503</td>\n",
       "      <td>0.029595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365490</th>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>603899.SH</td>\n",
       "      <td>-0.013610</td>\n",
       "      <td>0.015357</td>\n",
       "      <td>0.003817</td>\n",
       "      <td>-0.007294</td>\n",
       "      <td>-0.015680</td>\n",
       "      <td>-0.008104</td>\n",
       "      <td>-0.019157</td>\n",
       "      <td>-0.023037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010040</td>\n",
       "      <td>-0.009141</td>\n",
       "      <td>-0.003927</td>\n",
       "      <td>0.031939</td>\n",
       "      <td>-0.005566</td>\n",
       "      <td>-0.017145</td>\n",
       "      <td>-0.017852</td>\n",
       "      <td>-0.000767</td>\n",
       "      <td>-0.012375</td>\n",
       "      <td>-0.081653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365491 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TRADE_DT S_INFO_WINDCODE  Amount_20D_AVG  Amt2RealizedVolatility_5D  \\\n",
       "0      2016-01-04       000006.SZ        0.016521                  -0.001878   \n",
       "1      2016-01-04       000012.SZ        0.018360                   0.045949   \n",
       "2      2016-01-04       000021.SZ        0.007604                  -0.009174   \n",
       "3      2016-01-04       000028.SZ       -0.017967                  -0.012962   \n",
       "4      2016-01-04       000030.SZ       -0.025294                  -0.003740   \n",
       "...           ...             ...             ...                        ...   \n",
       "365486 2018-12-28       603877.SH       -0.031773                  -0.003502   \n",
       "365487 2018-12-28       603883.SH       -0.015326                   0.027342   \n",
       "365488 2018-12-28       603885.SH       -0.015847                   0.029671   \n",
       "365489 2018-12-28       603888.SH       -0.007538                   0.006159   \n",
       "365490 2018-12-28       603899.SH       -0.013610                   0.015357   \n",
       "\n",
       "              BP   CFP_ttm  CashDividendPayoutRatio   EBIT2EV     EPFY3  \\\n",
       "0      -0.013350 -0.050224                 0.039797  0.023656 -0.009673   \n",
       "1      -0.010283  0.008461                 0.041792 -0.013154 -0.004473   \n",
       "2       0.001322 -0.028544                -0.000120 -0.010430 -0.006332   \n",
       "3      -0.019874 -0.012101                -0.021628  0.006216  0.001504   \n",
       "4       0.003846  0.003205                 0.024752  0.005555 -0.012210   \n",
       "...          ...       ...                      ...       ...       ...   \n",
       "365486 -0.006375  0.002475                 0.027758  0.005939 -0.001940   \n",
       "365487 -0.007114  0.001327                 0.019745 -0.008971 -0.011490   \n",
       "365488 -0.005167  0.003013                -0.003062 -0.001466  0.002157   \n",
       "365489 -0.016373 -0.001432                 0.007393 -0.009854  0.001899   \n",
       "365490  0.003817 -0.007294                -0.015680 -0.008104 -0.019157   \n",
       "\n",
       "        EP_ded_qfa  ...  or_fy3_tb_120d  rank_pbroe_qfa  rank_peg_qfa2  \\\n",
       "0        -0.013850  ...        0.003320        0.002295      -0.023689   \n",
       "1        -0.025269  ...        0.018467        0.023287       0.032429   \n",
       "2         0.025829  ...       -0.001388        0.007405      -0.025029   \n",
       "3         0.012944  ...       -0.009309        0.013404       0.011113   \n",
       "4         0.011224  ...        0.002417        0.025218       0.011325   \n",
       "...            ...  ...             ...             ...            ...   \n",
       "365486   -0.004896  ...       -0.001255       -0.000130      -0.001532   \n",
       "365487   -0.003990  ...        0.002026       -0.003639      -0.001235   \n",
       "365488    0.006290  ...       -0.026506       -0.021470      -0.014746   \n",
       "365489   -0.012305  ...       -0.001168       -0.002947      -0.008553   \n",
       "365490   -0.023037  ...        0.010040       -0.009141      -0.003927   \n",
       "\n",
       "        rounte_mom       rtd  turnover1m  turnover3m  turnover_std_3m  \\\n",
       "0        -0.014387  0.008400    0.006687   -0.005394        -0.007455   \n",
       "1         0.063063 -0.011320    0.003509   -0.017234         0.001372   \n",
       "2        -0.010256  0.013120   -0.008876   -0.008485        -0.015728   \n",
       "3         0.000605 -0.003714    0.024293   -0.024580        -0.012023   \n",
       "4         0.036130  0.037349   -0.001005   -0.009503         0.003532   \n",
       "...            ...       ...         ...         ...              ...   \n",
       "365486    0.001229 -0.014368   -0.018003   -0.003988        -0.020923   \n",
       "365487   -0.006579  0.011113   -0.012099   -0.007568        -0.005972   \n",
       "365488    0.001025  0.013272   -0.010397   -0.010026        -0.005418   \n",
       "365489    0.001808 -0.001674    0.002796    0.002225        -0.005413   \n",
       "365490    0.031939 -0.005566   -0.017145   -0.017852        -0.000767   \n",
       "\n",
       "        varTradeVolume5_10      zdf5  \n",
       "0                -0.044167 -0.186898  \n",
       "1                -0.011703 -0.179700  \n",
       "2                 0.008078 -0.214747  \n",
       "3                 0.002113  0.000000  \n",
       "4                -0.013646 -0.172638  \n",
       "...                    ...       ...  \n",
       "365486           -0.014804 -0.020224  \n",
       "365487           -0.039398 -0.036857  \n",
       "365488            0.012436 -0.032721  \n",
       "365489            0.003503  0.029595  \n",
       "365490           -0.012375 -0.081653  \n",
       "\n",
       "[365491 rows x 114 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_date = Calender_all.TRADE_DT[0]\n",
    "# initial_date = '-'.join([initial_date[:4], initial_date[4:6], initial_date[6:]])\n",
    "Calender_train = Load_Calender(file_names, initial_date, n_train, time_unit, '日', date_begin=False)  # 加载初始训练集日期\n",
    "data_files_train = filter_file_name(file_names, Calender_train)\n",
    "    \n",
    "Index_date = Load_Index_Weights(conn, Calender_train)\n",
    "Index_date['TRADE_DT'] = pd.to_datetime(Index_date['TRADE_DT'], format='%Y%m%d')\n",
    "Index_date['month'] = Index_date['TRADE_DT'].dt.to_period('M')\n",
    "\n",
    "\n",
    "# 训练集要改 两种 对应\n",
    "train_data = read_data(data_files_train, response_type, unit, if_split = False)  #初始 全市场 训练集\n",
    "train_data['TRADE_DT'] = pd.to_datetime(train_data['TRADE_DT'], format='%Y%m%d')\n",
    "\n",
    "\n",
    "if orthogonalization:\n",
    "    train_data = train_data.groupby('TRADE_DT').apply(orthogonalize_factors_with_nan).reset_index(drop=True)\n",
    "\n",
    "if factor_to_zero:\n",
    "    train_data = train_data.groupby('TRADE_DT').apply(set_factors_to_zero).reset_index(drop=True)\n",
    "\n",
    "\n",
    "train_data['last_month'] = (train_data['TRADE_DT'] - pd.DateOffset(months=1)).dt.to_period('M')  \n",
    "\n",
    "data_500_list = []\n",
    "for month in Index_date['month'].unique():\n",
    "    code_500 = Index_date[Index_date['month'] == month]['S_INFO_WINDCODE']\n",
    "    data_500_list.append(train_data[(train_data['last_month']==month)&(train_data['S_INFO_WINDCODE'].isin(code_500))])\n",
    "        \n",
    "data_500 = pd.concat(data_500_list, ignore_index=True) #初始 500成分股 训练集\n",
    "\n",
    "del data_500['last_month']\n",
    "del train_data['last_month']\n",
    "\n",
    "data_500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据...:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据...: 100%|██████████| 20/20 [00:04<00:00,  4.72it/s]\n"
     ]
    }
   ],
   "source": [
    "date = initial_date\n",
    "if data_in_all:\n",
    "    train_set = train_data\n",
    "\n",
    "else:\n",
    "    train_set = data_500\n",
    "\n",
    "if validation_set:\n",
    "\n",
    "    Calender_append = get_next_date_validation(file_names, date, get_date_unit_validation)\n",
    "    last_date = datetime.strptime(Calender_append.TRADE_DT.tolist()[-1], '%Y%m%d')\n",
    "    date = next((day for day in Calender_all.TRADE_DT.tolist() if datetime.strptime(day, '%Y%m%d') > last_date), None)\n",
    "\n",
    "    data_files_append = filter_file_name(file_names, Calender_append)\n",
    "\n",
    "\n",
    "    data_append_validation = read_data(data_files_append, response_type, unit, if_split = False)  #添加 全市场数据\n",
    "    data_append_validation['TRADE_DT'] = pd.to_datetime(data_append_validation['TRADE_DT'], format='%Y%m%d')\n",
    "\n",
    "    if orthogonalization:\n",
    "        data_append_validation = data_append_validation.groupby('TRADE_DT').apply(orthogonalize_factors_with_nan).reset_index(drop=True)\n",
    "\n",
    "    if factor_to_zero:\n",
    "        data_append_validation = data_append_validation.groupby('TRADE_DT').apply(set_factors_to_zero).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    if not data_in_all:\n",
    "        # 添加的训练集属于   500成分股\n",
    "        Index_date = Load_Index_Weights(conn, Calender_append)      # 对应添加 500成分股的 时间跨度\n",
    "        Index_date['TRADE_DT'] = pd.to_datetime(Index_date['TRADE_DT'], format='%Y%m%d')\n",
    "        Index_date['month'] = Index_date['TRADE_DT'].dt.to_period('M')\n",
    "\n",
    "        data_append_validation['last_month'] = (data_append_validation['TRADE_DT'] - pd.DateOffset(months=1)).dt.to_period('M')\n",
    "\n",
    "        data_append_list = []\n",
    "\n",
    "        for month in Index_date['month'].unique():\n",
    "            code_500 = Index_date[Index_date['month'] == month]['S_INFO_WINDCODE']\n",
    "            data_append_list.append(data_append_validation[(data_append_validation['last_month'] == month) & (data_append_validation['S_INFO_WINDCODE'].isin(code_500))])\n",
    "\n",
    "        data_append_validation = pd.concat(data_append_list, ignore_index=True)\n",
    "        del data_append_validation['last_month']\n",
    "        #会改变因子列的顺序吗？\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#    validation_x = data_append_validation.iloc[:,:-1]\n",
    "    # 从中取出属于换仓日的部分\n",
    "#    validation_x = validation_x[validation_x['TRADE_DT'].isin(Calender_change['TRADE_DT'])]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 滚动训练和预测：在做预测之前进行对换仓日的筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据...: 100%|██████████| 240/240 [01:09<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练从2016-01-04到2018-12-28的模型\n",
      "训练从2019-01-02到2019-01-29的 valid 模型\n",
      "This is 1 th round\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.000000\n",
      "[LightGBM] [Debug] init for col-wise cost 0.002885 seconds, init for row-wise cost 0.461779 seconds\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.593752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28305\n",
      "[LightGBM] [Info] Number of data points in the train set: 2444448, number of used features: 111\n",
      "[LightGBM] [Info] Start training from score -0.000141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "test set 预测从2019-01-30到2020-01-23的模型\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据...: 100%|██████████| 240/240 [01:16<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练从2016-12-27到2019-12-25的模型\n",
      "训练从2019-12-26到2020-01-23的 valid 模型\n",
      "This is 1 th round\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.000000\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000276 seconds, init for row-wise cost 0.404170 seconds\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.574751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28305\n",
      "[LightGBM] [Info] Number of data points in the train set: 2645413, number of used features: 111\n",
      "[LightGBM] [Info] Start training from score -0.000036\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "test set 预测从2020-02-03到2021-01-20的模型\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据...: 100%|██████████| 240/240 [01:23<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练从2017-12-20到2020-12-22的模型\n",
      "训练从2020-12-23到2021-01-20的 valid 模型\n",
      "This is 1 th round\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.000000\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000385 seconds, init for row-wise cost 0.488029 seconds\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.622171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28305\n",
      "[LightGBM] [Info] Number of data points in the train set: 2811950, number of used features: 111\n",
      "[LightGBM] [Info] Start training from score 0.003570\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 3\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 3\n",
      "test set 预测从2021-01-21到2022-01-17的模型\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRADE_DT</th>\n",
       "      <th>S_INFO_WINDCODE</th>\n",
       "      <th>Amount_20D_AVG</th>\n",
       "      <th>Amt2RealizedVolatility_5D</th>\n",
       "      <th>BP</th>\n",
       "      <th>CFP_ttm</th>\n",
       "      <th>CashDividendPayoutRatio</th>\n",
       "      <th>EBIT2EV</th>\n",
       "      <th>EPFY3</th>\n",
       "      <th>EP_ded_qfa</th>\n",
       "      <th>...</th>\n",
       "      <th>or_fy3_tb_120d</th>\n",
       "      <th>rank_pbroe_qfa</th>\n",
       "      <th>rank_peg_qfa2</th>\n",
       "      <th>rounte_mom</th>\n",
       "      <th>rtd</th>\n",
       "      <th>turnover1m</th>\n",
       "      <th>turnover3m</th>\n",
       "      <th>turnover_std_3m</th>\n",
       "      <th>varTradeVolume5_10</th>\n",
       "      <th>predicted_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>0.043694</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.004871</td>\n",
       "      <td>0.037860</td>\n",
       "      <td>-0.033200</td>\n",
       "      <td>0.009854</td>\n",
       "      <td>-0.011826</td>\n",
       "      <td>0.024651</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009313</td>\n",
       "      <td>-0.007964</td>\n",
       "      <td>0.007334</td>\n",
       "      <td>0.011431</td>\n",
       "      <td>-0.010390</td>\n",
       "      <td>-0.020304</td>\n",
       "      <td>-0.007206</td>\n",
       "      <td>-0.002296</td>\n",
       "      <td>0.025118</td>\n",
       "      <td>-0.001608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>000002.SZ</td>\n",
       "      <td>0.046027</td>\n",
       "      <td>0.015797</td>\n",
       "      <td>-0.030397</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.014660</td>\n",
       "      <td>0.025622</td>\n",
       "      <td>-0.018617</td>\n",
       "      <td>-0.008623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001821</td>\n",
       "      <td>-0.004565</td>\n",
       "      <td>0.015289</td>\n",
       "      <td>0.008930</td>\n",
       "      <td>0.008016</td>\n",
       "      <td>-0.002926</td>\n",
       "      <td>-0.001588</td>\n",
       "      <td>0.003371</td>\n",
       "      <td>0.019819</td>\n",
       "      <td>-0.002711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>000004.SZ</td>\n",
       "      <td>-0.026611</td>\n",
       "      <td>-0.018814</td>\n",
       "      <td>-0.017500</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.011452</td>\n",
       "      <td>-0.004221</td>\n",
       "      <td>-0.001483</td>\n",
       "      <td>0.012576</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>-0.037702</td>\n",
       "      <td>0.003878</td>\n",
       "      <td>0.006902</td>\n",
       "      <td>0.009842</td>\n",
       "      <td>-0.001514</td>\n",
       "      <td>-0.014743</td>\n",
       "      <td>-0.006913</td>\n",
       "      <td>0.009518</td>\n",
       "      <td>-0.000115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>000005.SZ</td>\n",
       "      <td>0.023593</td>\n",
       "      <td>0.003291</td>\n",
       "      <td>-0.007984</td>\n",
       "      <td>-0.011775</td>\n",
       "      <td>-0.011305</td>\n",
       "      <td>0.012751</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.002910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>-0.029763</td>\n",
       "      <td>-0.034087</td>\n",
       "      <td>-0.013565</td>\n",
       "      <td>0.007271</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.015479</td>\n",
       "      <td>0.007370</td>\n",
       "      <td>0.017462</td>\n",
       "      <td>-0.002711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>000006.SZ</td>\n",
       "      <td>0.013612</td>\n",
       "      <td>0.016984</td>\n",
       "      <td>-0.012417</td>\n",
       "      <td>-0.002931</td>\n",
       "      <td>0.018786</td>\n",
       "      <td>0.024067</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>-0.031150</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001369</td>\n",
       "      <td>0.031571</td>\n",
       "      <td>-0.014952</td>\n",
       "      <td>0.014012</td>\n",
       "      <td>-0.004704</td>\n",
       "      <td>-0.007253</td>\n",
       "      <td>0.006883</td>\n",
       "      <td>-0.003307</td>\n",
       "      <td>-0.007468</td>\n",
       "      <td>-0.002675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600127</th>\n",
       "      <td>2022-01-11</td>\n",
       "      <td>873169.BJ</td>\n",
       "      <td>-0.000710</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>-0.003949</td>\n",
       "      <td>-0.000613</td>\n",
       "      <td>-0.005894</td>\n",
       "      <td>0.001651</td>\n",
       "      <td>-0.000733</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001082</td>\n",
       "      <td>0.003813</td>\n",
       "      <td>0.003060</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>-0.003552</td>\n",
       "      <td>-0.004465</td>\n",
       "      <td>-0.002607</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.010223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600128</th>\n",
       "      <td>2022-01-11</td>\n",
       "      <td>873223.BJ</td>\n",
       "      <td>-0.000717</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>-0.003983</td>\n",
       "      <td>-0.000616</td>\n",
       "      <td>-0.005945</td>\n",
       "      <td>0.001666</td>\n",
       "      <td>-0.000737</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001090</td>\n",
       "      <td>0.003860</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>-0.003580</td>\n",
       "      <td>-0.004505</td>\n",
       "      <td>-0.002622</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.010223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600129</th>\n",
       "      <td>2022-01-11</td>\n",
       "      <td>873305.BJ</td>\n",
       "      <td>-0.000717</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>-0.003983</td>\n",
       "      <td>-0.000616</td>\n",
       "      <td>-0.005945</td>\n",
       "      <td>0.001666</td>\n",
       "      <td>-0.000737</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001090</td>\n",
       "      <td>0.003860</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>-0.003580</td>\n",
       "      <td>-0.004505</td>\n",
       "      <td>-0.002622</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.010223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600130</th>\n",
       "      <td>2022-01-11</td>\n",
       "      <td>873339.BJ</td>\n",
       "      <td>-0.000717</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>-0.003983</td>\n",
       "      <td>-0.000616</td>\n",
       "      <td>-0.005945</td>\n",
       "      <td>0.001666</td>\n",
       "      <td>-0.000737</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001090</td>\n",
       "      <td>0.003860</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>-0.003580</td>\n",
       "      <td>-0.004505</td>\n",
       "      <td>-0.002622</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.010223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600131</th>\n",
       "      <td>2022-01-11</td>\n",
       "      <td>873527.BJ</td>\n",
       "      <td>-0.000717</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>-0.003983</td>\n",
       "      <td>-0.000616</td>\n",
       "      <td>-0.005945</td>\n",
       "      <td>0.001666</td>\n",
       "      <td>-0.000737</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001090</td>\n",
       "      <td>0.003860</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>-0.003580</td>\n",
       "      <td>-0.004505</td>\n",
       "      <td>-0.002622</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.010223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600132 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TRADE_DT S_INFO_WINDCODE  Amount_20D_AVG  Amt2RealizedVolatility_5D  \\\n",
       "0      2019-01-30       000001.SZ        0.043694                   0.002485   \n",
       "1      2019-01-30       000002.SZ        0.046027                   0.015797   \n",
       "2      2019-01-30       000004.SZ       -0.026611                  -0.018814   \n",
       "3      2019-01-30       000005.SZ        0.023593                   0.003291   \n",
       "4      2019-01-30       000006.SZ        0.013612                   0.016984   \n",
       "...           ...             ...             ...                        ...   \n",
       "600127 2022-01-11       873169.BJ       -0.000710                   0.000539   \n",
       "600128 2022-01-11       873223.BJ       -0.000717                   0.000545   \n",
       "600129 2022-01-11       873305.BJ       -0.000717                   0.000545   \n",
       "600130 2022-01-11       873339.BJ       -0.000717                   0.000545   \n",
       "600131 2022-01-11       873527.BJ       -0.000717                   0.000545   \n",
       "\n",
       "              BP   CFP_ttm  CashDividendPayoutRatio   EBIT2EV     EPFY3  \\\n",
       "0       0.004871  0.037860                -0.033200  0.009854 -0.011826   \n",
       "1      -0.030397  0.012712                 0.014660  0.025622 -0.018617   \n",
       "2      -0.017500  0.000001                -0.011452 -0.004221 -0.001483   \n",
       "3      -0.007984 -0.011775                -0.011305  0.012751  0.000463   \n",
       "4      -0.012417 -0.002931                 0.018786  0.024067 -0.000171   \n",
       "...          ...       ...                      ...       ...       ...   \n",
       "600127 -0.003949 -0.000613                -0.005894  0.001651 -0.000733   \n",
       "600128 -0.003983 -0.000616                -0.005945  0.001666 -0.000737   \n",
       "600129 -0.003983 -0.000616                -0.005945  0.001666 -0.000737   \n",
       "600130 -0.003983 -0.000616                -0.005945  0.001666 -0.000737   \n",
       "600131 -0.003983 -0.000616                -0.005945  0.001666 -0.000737   \n",
       "\n",
       "        EP_ded_qfa  ...  or_fy3_tb_120d  rank_pbroe_qfa  rank_peg_qfa2  \\\n",
       "0         0.024651  ...       -0.009313       -0.007964       0.007334   \n",
       "1        -0.008623  ...        0.001821       -0.004565       0.015289   \n",
       "2         0.012576  ...       -0.000089       -0.037702       0.003878   \n",
       "3         0.002910  ...        0.000201       -0.029763      -0.034087   \n",
       "4        -0.031150  ...       -0.001369        0.031571      -0.014952   \n",
       "...            ...  ...             ...             ...            ...   \n",
       "600127    0.000487  ...       -0.001082        0.003813       0.003060   \n",
       "600128    0.000491  ...       -0.001090        0.003860       0.003092   \n",
       "600129    0.000491  ...       -0.001090        0.003860       0.003092   \n",
       "600130    0.000491  ...       -0.001090        0.003860       0.003092   \n",
       "600131    0.000491  ...       -0.001090        0.003860       0.003092   \n",
       "\n",
       "        rounte_mom       rtd  turnover1m  turnover3m  turnover_std_3m  \\\n",
       "0         0.011431 -0.010390   -0.020304   -0.007206        -0.002296   \n",
       "1         0.008930  0.008016   -0.002926   -0.001588         0.003371   \n",
       "2         0.006902  0.009842   -0.001514   -0.014743        -0.006913   \n",
       "3        -0.013565  0.007271    0.000007   -0.015479         0.007370   \n",
       "4         0.014012 -0.004704   -0.007253    0.006883        -0.003307   \n",
       "...            ...       ...         ...         ...              ...   \n",
       "600127    0.000421 -0.000143   -0.003552   -0.004465        -0.002607   \n",
       "600128    0.000427 -0.000143   -0.003580   -0.004505        -0.002622   \n",
       "600129    0.000427 -0.000143   -0.003580   -0.004505        -0.002622   \n",
       "600130    0.000427 -0.000143   -0.003580   -0.004505        -0.002622   \n",
       "600131    0.000427 -0.000143   -0.003580   -0.004505        -0.002622   \n",
       "\n",
       "        varTradeVolume5_10  predicted_y  \n",
       "0                 0.025118    -0.001608  \n",
       "1                 0.019819    -0.002711  \n",
       "2                 0.009518    -0.000115  \n",
       "3                 0.017462    -0.002711  \n",
       "4                -0.007468    -0.002675  \n",
       "...                    ...          ...  \n",
       "600127            0.000678     0.010223  \n",
       "600128            0.000679     0.010223  \n",
       "600129            0.000679     0.010223  \n",
       "600130            0.000679     0.010223  \n",
       "600131            0.000679     0.010223  \n",
       "\n",
       "[600132 rows x 114 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def find_best_model(param_grid,train_x,train_y,validation_x,validation_y):\n",
    "    best_error = float('inf') #误差越小越好\n",
    "    best_model = None\n",
    "    i = 1\n",
    "    for max_depth in param_grid['max_depth']: #网格搜索最佳参数\n",
    "        for learning_rate in param_grid['learning_rate']:\n",
    "            for n_estimators in param_grid['n_estimators']:\n",
    "                print(f\"This is {i} th round\")\n",
    "                params = {'n_estimators': n_estimators,\n",
    "                        'max_depth': max_depth,\n",
    "                        'num_leaves': 64,\n",
    "                        'min_child_samples': 240,\n",
    "                        'min_child_weight': 0.001,\n",
    "                        'subsample': 0.8,\n",
    "                        'colsample_bytree': 0.8,\n",
    "                        'reg_alpha': 0,\n",
    "                        'reg_lambda': 0,\n",
    "                        'learning_rate': learning_rate,\n",
    "                        'boosting_type': 'gbdt',\n",
    "                        #                                   'early_stopping_round': 5,\n",
    "                        'objective': 'regression',\n",
    "                        'verbosity': 2\n",
    "                        }  # 默认参数 \n",
    "                lgb_model = lgb.LGBMRegressor(**params)\n",
    "                lgb_model.fit(train_x.drop(['TRADE_DT', 'S_INFO_WINDCODE'], axis=1), train_y)\n",
    "\n",
    "                test_y_validation = lgb_model.predict(validation_x.drop(['TRADE_DT', 'S_INFO_WINDCODE'], axis=1))\n",
    "                error = mean_squared_error(validation_y, test_y_validation)\n",
    "                if error < best_error:\n",
    "                    best_model = lgb_model\n",
    "                    best_error = error\n",
    "                i += 1\n",
    "\n",
    "    return best_error, best_model\n",
    "\n",
    "\n",
    "test_y_predict_list = []\n",
    "\n",
    "\n",
    "\n",
    "# expand a test_set first in the while loop\n",
    "while date in Calender_all.TRADE_DT.tolist():\n",
    "    # print('date' + date)\n",
    "    # 接下来是对训练集的按周/月添加，同时作为新的一周/月，也是测试集\n",
    "    # Calender_append = Load_Calender(file_names, date, rolling_window, rolling_unit, '日', date_begin=True)\n",
    "    Calender_append = get_next_date(file_names, date, get_date_unit)\n",
    "    last_date = datetime.strptime(Calender_append.TRADE_DT.tolist()[-1], '%Y%m%d')\n",
    "    date = next((day for day in Calender_all.TRADE_DT.tolist() if datetime.strptime(day, '%Y%m%d') > last_date), None)\n",
    "\n",
    "    data_files_append = filter_file_name(file_names, Calender_append) \n",
    "    \n",
    "    \n",
    "    data_append = read_data(data_files_append, response_type, unit, if_split = False)  #添加 全市场数据\n",
    "    data_append['TRADE_DT'] = pd.to_datetime(data_append['TRADE_DT'], format='%Y%m%d')\n",
    "\n",
    "    if orthogonalization:\n",
    "        data_append = data_append.groupby('TRADE_DT').apply(orthogonalize_factors_with_nan).reset_index(drop=True)\n",
    "\n",
    "    if factor_to_zero:\n",
    "        data_append = data_append.groupby('TRADE_DT').apply(set_factors_to_zero).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    if not data_in_all:\n",
    "        # 添加的训练集属于   500成分股\n",
    "        Index_date = Load_Index_Weights(conn, Calender_append)      # 对应添加 500成分股的 时间跨度\n",
    "        Index_date['TRADE_DT'] = pd.to_datetime(Index_date['TRADE_DT'], format='%Y%m%d')\n",
    "        Index_date['month'] = Index_date['TRADE_DT'].dt.to_period('M')\n",
    "\n",
    "        data_append['last_month'] = (data_append['TRADE_DT'] - pd.DateOffset(months=1)).dt.to_period('M')   \n",
    "        \n",
    "        data_append_list = []\n",
    "\n",
    "        for month in Index_date['month'].unique():\n",
    "            code_500 = Index_date[Index_date['month'] == month]['S_INFO_WINDCODE']\n",
    "            data_append_list.append(data_append[(data_append['last_month'] == month) & (data_append['S_INFO_WINDCODE'].isin(code_500))])\n",
    "        \n",
    "        data_append = pd.concat(data_append_list, ignore_index=True)\n",
    "        del data_append['last_month']  \n",
    "        #会改变因子列的顺序吗？ \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    train_x = train_set.iloc[:,:-1]\n",
    "    train_y = train_set.iloc[:,-1]\n",
    "    test_x = data_append.iloc[:,:-1]\n",
    "\n",
    "    # # 从中取出属于换仓日的部分\n",
    "    test_x = test_x[test_x['TRADE_DT'].isin(Calender_change['TRADE_DT'])]\n",
    "    # test_y = data_append.iloc[:,-1]\n",
    "\n",
    "\n",
    "    # 训练模型\n",
    "    start = train_set.TRADE_DT[0].strftime('%Y-%m-%d')\n",
    "    end = train_set.TRADE_DT.iloc[-1].strftime('%Y-%m-%d')   \n",
    "    \n",
    "    print('训练从' + start + '到' + end + '的模型') ##这是 test setting\n",
    "\n",
    "\n",
    "\n",
    "    if validation_set:\n",
    "        validation_x = data_append_validation.iloc[:,:-1]\n",
    "        validation_y = data_append_validation.iloc[:,-1]\n",
    "\n",
    "\n",
    "    ###### add validation set\n",
    "        \n",
    "        start = data_append_validation.TRADE_DT.iloc[0].strftime('%Y-%m-%d')\n",
    "        end = data_append_validation.TRADE_DT.iloc[-1].strftime('%Y-%m-%d') \n",
    "        print('训练从' + start + '到' + end + '的 valid 模型')\n",
    "        best_error, best_model = find_best_model(param_grid,train_x,train_y,validation_x,validation_y)\n",
    "\n",
    "        # 清内存\n",
    "        del validation_x, validation_y ## delete here?\n",
    "    else:\n",
    "        best_error, best_model = find_best_model(param_grid,train_x,train_y,train_x,train_y) #无验证集就把训练集当验证集\n",
    "\n",
    "\n",
    "    start = data_append.TRADE_DT[0].strftime('%Y-%m-%d')\n",
    "    end = data_append.TRADE_DT.iloc[-1].strftime('%Y-%m-%d')\n",
    "    \n",
    "    print('test set 预测从' + start + '到' + end + '的模型')\n",
    "    test_y_predict = Get_FACTOR_Neu(test_x, best_model, if_regression = True)\n",
    "    test_y_predict_list.append(test_y_predict)\n",
    "\n",
    "   \n",
    "    if validation_set:\n",
    "        # merge validationn set and test set\n",
    "        valid_and_test = pd.concat([data_append_validation,data_append], ignore_index=True)\n",
    "        # front_set and back_set\n",
    "        Calender_front = get_next_date(file_names, data_append_validation.TRADE_DT.iloc[0].strftime('%Y%m%d'), get_date_unit)\n",
    "        Calender_front['TRADE_DT'] = pd.to_datetime(Calender_front['TRADE_DT'], format='%Y%m%d')\n",
    "        front_set = valid_and_test[valid_and_test['TRADE_DT'].isin(Calender_front['TRADE_DT'])]\n",
    "        back_set = valid_and_test[~valid_and_test['TRADE_DT'].isin(Calender_front['TRADE_DT'])]\n",
    "        back_set.index = [i for i in range(len(back_set))]\n",
    "        # merge train_set with front_set\n",
    "        train_set = pd.concat([train_set, front_set], ignore_index=True)\n",
    "        # up_date validation set to back_set\n",
    "        data_append_validation = back_set\n",
    "        del valid_and_test, front_set, back_set\n",
    "\n",
    "\n",
    "    else:\n",
    "        train_set = pd.concat([train_set, data_append], ignore_index=True)\n",
    "\n",
    "    # 清内存 (可以考虑提前清理 train_x,train_y)\n",
    "    del train_x, train_y, test_x\n",
    "\n",
    "        #记录最优参数\n",
    "    # best_params = best_model.get_params()\n",
    "    # best_params_str = \"_\".join(f\"{k}={v}\" for k, v in best_params.items() if k in param_grid)\n",
    "\n",
    "\n",
    "    # 把测试集拼入训练集中作为下一次的训练集 （这是没有验证集的情况）\n",
    "    # train_set = pd.concat([train_set, data_append], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "    # add a test set for one year, and the one add first above is validation set\n",
    "\n",
    "\n",
    "    if rolling_style:\n",
    "        Calender_drop = get_next_date(file_names, train_set.TRADE_DT[0].strftime('%Y%m%d'), get_date_unit)\n",
    "        Calender_drop['TRADE_DT'] = pd.to_datetime(Calender_drop['TRADE_DT'], format='%Y%m%d')\n",
    "        train_set = train_set[~train_set['TRADE_DT'].isin(Calender_drop['TRADE_DT'])]\n",
    "        train_set.index = [i for i in range(len(train_set))]\n",
    "\n",
    "\n",
    "\n",
    "# 拼接预测结果    \n",
    "y_predict_df = pd.concat(test_y_predict_list, ignore_index=True)\n",
    "y_predict_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分年度多头组绩效回测: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predict_df.to_pickle(y_predict_name)\n",
    "y_predict_name = '_4_0.2_400.pkl'\n",
    "y_predict_df = pd.read_pickle(y_predict_name)\n",
    "grouped = y_predict_df.groupby(y_predict_df['TRADE_DT'].dt.year)\n",
    "\n",
    "# 将每个年份的DataFrame存储在一个列表中\n",
    "result = [group for _, group in grouped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_df[['TRADE_DT', 'S_INFO_WINDCODE', 'SUE_drift_excl_qfa', 'predicted_y']] #why SUE_drift_excl_qfa ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全程多头组绩效回测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factor = y_predict_df[['TRADE_DT', 'S_INFO_WINDCODE', 'SUE_drift_excl_qfa']]  #why SUE_drift_excl_qfa ???\n",
    "# Factor = Factor.rename(columns={'SUE_drift_excl_qfa': 'FACTOR'})\n",
    "\n",
    "\n",
    "Factor = y_predict_df[['TRADE_DT', 'S_INFO_WINDCODE', 'predicted_y']]  # try pred_y\n",
    "Factor = Factor.rename(columns={'predicted_y': 'FACTOR'})\n",
    "\n",
    "Factor['TRADE_DT'] = pd.to_datetime(Factor['TRADE_DT'], format='%Y/%m/%d', errors='coerce')\n",
    "Factor['TRADE_DT'] = Factor['TRADE_DT'].dt.strftime('%Y%m%d')\n",
    "\n",
    "Calender_all = pd.DataFrame({'TRADE_DT': Factor.TRADE_DT.unique()})\n",
    "Risk_free_file = 'Input/副本无风险利率.xlsx'  # 无风险利率数据路径\n",
    "RiskFreeReturn = LoadRiskFreeReturn(Risk_free_file, Calender_all)  # 加载无风险利率数据\n",
    "Price, MarketCap, Industry, ST, Suspend, ListDate = Load_SQLData(conn, Calender_all, False, OutputPath_result,\n",
    "                                                                 local=data_local)  # 加载SQL数据\n",
    "BenchReturn = Load_Return(conn, Calender_all)  # 加载基准收益\n",
    "\n",
    "Factor_all = Cal_Sift(Factor, ST, Suspend, ListDate)\n",
    "GroupNum = 10\n",
    "Factor_Group = Cal_Stratify(Factor_all, GroupNum)\n",
    "# 获取分组持仓的股票池\n",
    "Hold = Factor_Group[Factor_Group['GROUP'] == str(1)][['TRADE_DT', 'S_INFO_WINDCODE']].reset_index(drop=True)\n",
    "# 根据持仓股票池，生成仓位数据\n",
    "Position = Cal_Position(Hold)\n",
    "Position['date'] = pd.to_datetime(Position['TRADE_DT'], format='%Y%m%d')\n",
    "# 调用回测函数\n",
    "NetValueTmp, PerformTmp = Back_Testing(Position, Price, BenchReturn, RiskFreeReturn)\n",
    "NetValueTmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NetValueTmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PerformTmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分年度多头组绩效回测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NetValueTmp.index = pd.to_datetime(NetValueTmp.index, format='%Y%m%d')\n",
    "grouped = NetValueTmp.groupby(NetValueTmp.index.year)\n",
    "df_list = [(_, group) for _, group in grouped]\n",
    "year_list = [year for year, group in grouped]\n",
    "Perform = pd.DataFrame(columns=['年化收益(%)', '基准年化收益(%)', '超额年化收益(%)',\n",
    "                                '超额年化波动(%)', '信息比率', '超额最大回撤(%)', '胜率(%)', '换手率(年均)'], index=year_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year, group in df_list:\n",
    "    Return = pd.DataFrame(group[['策略净值', '策略收益']])\n",
    "    Return.rename(columns={'策略净值': 'NETVALUE'}, inplace=True)\n",
    "    Return.rename(columns={'策略收益': 'RETURN'}, inplace=True)\n",
    "    Position_year = Position[Position['date'].dt.year == year]\n",
    "    \n",
    "    Calender = pd.DataFrame({'TRADE_DT': [timestamp.strftime('%Y%m%d') for timestamp in group.index]})\n",
    "    Risk_free_file = 'Input/副本无风险利率.xlsx'  # 无风险利率数据路径\n",
    "    RiskFreeReturn = LoadRiskFreeReturn(Risk_free_file, Calender)  # 加载无风险利率数据\n",
    "    BenchReturn = Load_Return(conn, Calender)\n",
    "    \n",
    "    # 换手率\n",
    "    TurnOverRate = Cal_TurnOver(Position_year)\n",
    "    # 无风险收益：\n",
    "    RiskfreeReturn, RiskfreeIntervalRet, RiskfreeIntervaStd, RiskfreeAnnualRet, RiskfreeAnnualStd, RiskfreeMaxdrawdown = PerfStatis(\n",
    "        RiskFreeReturn, frequency='D')\n",
    "    \n",
    "    # 基准收益：\n",
    "    # BenchReturn.loc[BenchReturn.index <= PeriodList[0], 'RETURN'] = 0 #这一句是否需要删除，有待验证\n",
    "    BenchReturn, BenchIntervalRet, BenchIntervaStd, BenchAnnualRet, BenchAnnualStd, BenchMaxdrawdown = PerfStatis(\n",
    "        BenchReturn, frequency='D')\n",
    "    \n",
    "    # 策略收益：\n",
    "    StrategyReturn, StrategyIntervalRet, StrategyIntervaStd, StrategyAnnualRet, StrategyAnnualStd, StrategyMaxdrawdown = PerfStatis(\n",
    "        Return, frequency='D', if_Returned=False)\n",
    "    \n",
    "    # 超额收益：\n",
    "    initial_ExcessReturn = Cal_Excess(StrategyReturn, BenchReturn)\n",
    "    ExcessReturn, ExcessIntervalRet, ExcessIntervaStd, ExcessAnnualRet, ExcessAnnualStd, ExcessMaxdrawdown = PerfStatis(\n",
    "        initial_ExcessReturn, frequency='D', if_Returned=False)\n",
    "    \n",
    "    # 胜率：\n",
    "    StrategyWinper = Cal_Winper(ExcessReturn)\n",
    "    # 汇总：\n",
    "    Perform.loc[year, :] = StrategyAnnualRet, BenchAnnualRet, ExcessAnnualRet, ExcessAnnualStd, (\n",
    "        ExcessAnnualRet-RiskfreeAnnualRet)/ExcessAnnualStd, ExcessMaxdrawdown, StrategyWinper, TurnOverRate\n",
    "\n",
    "\n",
    "# 同全程汇总\n",
    "new_row = pd.DataFrame(PerformTmp[['年化收益(%)', '基准年化收益(%)', '超额年化收益(%)',\n",
    "                       '超额年化波动(%)', '信息比率', '超额最大回撤(%)', '胜率(%)', '换手率(年均)']].values, index=['整体'])\n",
    "new_row.columns = Perform.columns\n",
    "\n",
    "\n",
    "\n",
    "Perform = pd.concat([Perform, new_row])\n",
    "Perform\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NetValueTmp['超额回撤'] = 0  # 初始化最大回撤列为0\n",
    "max_drawdown = 0  # 当前的最大回撤值\n",
    "for i in range(len(NetValueTmp)):\n",
    "    max_value = NetValueTmp['相对净值'][:i+1].max()  # 从第一天到当前天的最大净值\n",
    "    drawdown = 100 * (NetValueTmp['相对净值'][i] / max_value - 1)  # 当前天的回撤\n",
    "    max_drawdown = min(max_drawdown, drawdown)  # 更新当前的最大回撤值\n",
    "    NetValueTmp['超额回撤'].iloc[i] = max_drawdown\n",
    "\n",
    "del NetValueTmp['策略收益']\n",
    "NetValueTmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结果存储及净值曲线绘制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excel文件名称可能需要手动更改\n",
    "writer = pd.ExcelWriter(OutputPath_result + '/' + result_excel)\n",
    "\n",
    "# 将DataFrame写入不同的sheet\n",
    "NetValueTmp.index = NetValueTmp.index.strftime('%Y-%m-%d')\n",
    "Perform.to_excel(writer, sheet_name='多头组绩效', index=True)\n",
    "NetValueTmp.to_excel(writer, sheet_name='多头组全程净值', index=True)\n",
    "\n",
    "# 保存Excel文件\n",
    "writer.save()\n",
    "\n",
    "# 关闭ExcelWriter对象\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 15))  # 设置图形大小\n",
    "\n",
    "\n",
    "\n",
    "# 遍历DataFrame的每一列，为每一列绘制一条线，并设置标签为列名\n",
    "for column in NetValueTmp.columns:\n",
    "    plt.plot(NetValueTmp[column], label=column)\n",
    "\n",
    "plt.xlabel('日期')  # 设置x轴标签\n",
    "plt.ylabel('净值')  # 设置y轴标签\n",
    "plt.title('分组超额折线图')  # 设置标题\n",
    "plt.legend(loc='upper left', fontsize='x-large')  # 显示图例\n",
    "\n",
    "x = np.arange(0, len(NetValueTmp.index), 100)  # 每100个数据点显示一个刻度\n",
    "\n",
    "\n",
    "locs, labels = plt.xticks(NetValueTmp.index[x], rotation=45)  # 设置x轴刻度标签并旋转45度\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 组合优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predict_df.to_pickle(y_predict_name)\n",
    "y_predict_name = '_4_0.2_400.pkl'\n",
    "y_predict_df = pd.read_pickle(y_predict_name)\n",
    "grouped = y_predict_df.groupby(y_predict_df['TRADE_DT'].dt.year)\n",
    "\n",
    "# 将每个年份的DataFrame存储在一个列表中\n",
    "result = [group for _, group in grouped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_df['SUE_drift_excl_qfa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Factor = y_predict_df[['TRADE_DT', 'S_INFO_WINDCODE', 'SUE_drift_excl_qfa']]\n",
    "Factor = Factor.rename(columns={'SUE_drift_excl_qfa': 'FACTOR'})\n",
    "Factor['TRADE_DT'] = pd.to_datetime(\n",
    "    Factor['TRADE_DT'], format='%Y/%m/%d', errors='coerce')\n",
    "Factor['TRADE_DT'] = Factor['TRADE_DT'].dt.strftime('%Y%m%d')\n",
    "\n",
    "Calender_all = pd.DataFrame({'TRADE_DT': Factor.TRADE_DT.unique()})\n",
    "Risk_free_file = 'Input/副本无风险利率.xlsx'  # 无风险利率数据路径\n",
    "RiskFreeReturn = LoadRiskFreeReturn(Risk_free_file, Calender_all)  # 加载无风险利率数据\n",
    "Price, MarketCap, Industry, ST, Suspend, ListDate = Load_SQLData(conn, Calender_all, False, OutputPath_result,\n",
    "                                                                 local=data_local)  # 加载SQL数据\n",
    "# Weight = pd.read_pickle(r'D:\\Microsoft VS Code\\Code_repository\\GuoJun\\model_output_all\\Weight.pkl')\n",
    "Weight = pd.read_csv(\n",
    "    r'D:\\新建文件夹 (4)\\WeChat Files\\wxid_o6h4331nu3f012\\FileStorage\\File\\2023-12\\zscfgday000905.csv')\n",
    "Weight = Weight[['trade_dt', 's_info_windcode', 'i_weight']].rename(\n",
    "    columns={'trade_dt': 'TRADE_DT', 's_info_windcode': 'S_INFO_WINDCODE', 'i_weight': 'ADJ_I_WEIGHT'})\n",
    "Weight = Weight[Weight['ADJ_I_WEIGHT'].notnull()]\n",
    "Weight.index = range(len(Weight))\n",
    "Weight.ADJ_I_WEIGHT = Weight.ADJ_I_WEIGHT/100\n",
    "Weight['TRADE_DT'] = Weight['TRADE_DT'].str.replace('-', '')\n",
    "BenchReturn = Load_Return(conn, Calender_all)  # 加载基准收益\n",
    "\n",
    "Factor_all = Cal_Sift(Factor, ST, Suspend, ListDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position_Optimal = Factor_all[['TRADE_DT', 'S_INFO_WINDCODE']]\n",
    "# Position_Optimal['POSITION'] = np.zeros(len(Position_Optimal))\n",
    "Position_list = []\n",
    "Error_date_list = []\n",
    "drop_list = []\n",
    "\n",
    "Industry_list = Industry.IND_CODE.unique().tolist()\n",
    "i = 0\n",
    "# 遍历每一个交易日\n",
    "for Date in tqdm(Factor_all.TRADE_DT.unique()[1:-40]):\n",
    "    \n",
    "    # 取行业代码和因子值\n",
    "    Industry_list = Industry.IND_CODE.unique().tolist()\n",
    "    Factor_Day = Factor_all[Factor_all['TRADE_DT'] == Date]\n",
    "    Factor_Day.index = range(len(Factor_Day))\n",
    "    \n",
    "    # 在2023年后，存在部分股票的行业不存在于industry，删除这部分股票\n",
    "    for index, code in enumerate(Factor_Day['S_INFO_WINDCODE']):\n",
    "        if len(Industry.loc[Industry['S_INFO_WINDCODE'] == code]) == 0:\n",
    "            drop_list.append(code)\n",
    "    Factor_Day = Factor_Day[~Factor_Day['S_INFO_WINDCODE'].isin(drop_list)]\n",
    "    \n",
    "    # 取因子值\n",
    "    # MU = Factor_all[Factor_all['TRADE_DT'] == Date]\n",
    "    MU = pd.DataFrame(Factor_Day['FACTOR'].values)\n",
    "    \n",
    "    # 计算行业暴露，构造行业中性约束\n",
    "    beq = pd.DataFrame(0, index=range(len(Industry_list)), columns=[0])\n",
    "    Aeq = pd.DataFrame(0, index=range(len(Industry_list)),\n",
    "                   columns=range(len(Factor_Day)))\n",
    "    for index, code in enumerate(Factor_Day['S_INFO_WINDCODE']):\n",
    "        ind = Industry.loc[Industry['S_INFO_WINDCODE']\n",
    "                       == code, 'IND_CODE'].values[0]\n",
    "        Aeq.iloc[Industry_list.index(ind), index] = 1\n",
    "    \n",
    "    # 计算市值暴露，构造市值中性约束\n",
    "    MarketCap_Day = MarketCap[MarketCap['TRADE_DT'] == Date]\n",
    "    MarketCap_Day = MarketCap_Day[MarketCap_Day.S_INFO_WINDCODE.isin(\n",
    "        Factor_Day.S_INFO_WINDCODE.tolist())]\n",
    "    log_market_value = np.log(MarketCap_Day['S_VAL_MV'])\n",
    "    mean = np.sum(log_market_value *\n",
    "              MarketCap_Day['S_VAL_MV']) / np.sum(MarketCap_Day['S_VAL_MV'])\n",
    "\n",
    "    std = MarketCap_Day['S_VAL_MV'].std()\n",
    "    MarketCap_Day['VALMV_Expose'] = (log_market_value - mean) / std\n",
    "\n",
    "    A_leq = pd.concat([pd.DataFrame(MarketCap_Day.VALMV_Expose.to_numpy()).T,\n",
    "                   pd.DataFrame(-MarketCap_Day.VALMV_Expose.to_numpy()).T])\n",
    "\n",
    "    b_leq = pd.DataFrame([0.5, 0.5])\n",
    "    \n",
    "    # Weight_Day['ADJ_I_WEIGHT'] = Weight_Day['ADJ_I_WEIGHT']*100\n",
    "    # 取基准指数权重\n",
    "    Weight_Day = Weight[Weight['TRADE_DT'] == Date]\n",
    "    bmw_Day = pd.DataFrame(\n",
    "        {'TRADE_DT': Factor_Day.TRADE_DT, 'S_INFO_WINDCODE': Factor_Day.S_INFO_WINDCODE, 'Weight': np.zeros(len(Factor_Day))})  # 基准指数权重\n",
    "\n",
    "    for code in bmw_Day.S_INFO_WINDCODE:\n",
    "        if code in Weight_Day.S_INFO_WINDCODE.tolist():\n",
    "            bmw_Day.loc[bmw_Day.S_INFO_WINDCODE == code,\n",
    "                        'Weight'] = Weight_Day.loc[Weight_Day.S_INFO_WINDCODE == code, 'ADJ_I_WEIGHT'].values\n",
    "    \n",
    "    Price_Day = Price[Price['TRADE_DT'] == Date]\n",
    "    Price_Day = Price_Day[Price_Day.S_INFO_WINDCODE.isin(Factor_Day.S_INFO_WINDCODE.tolist())]\n",
    "    Price_Day.index = range(len(Price_Day))\n",
    "    \n",
    "    # 初始主动权重为基准指数权重，否则为上一期的主动权重\n",
    "    bmw = pd.DataFrame(bmw_Day.Weight.values).T\n",
    "    if i == 0:\n",
    "        w0 = bmw - bmw\n",
    "    else:\n",
    "        # w0 = pd.DataFrame(a11).T \n",
    "    # 取收盘价，用于计算每一期间权重变化\n",
    "        \n",
    "        Weight_new = Factor_Day.merge(Weight_final, on='S_INFO_WINDCODE',\n",
    "                                    how='left')\n",
    "        Weight_new['S_DQ_ADJCLOSE_NEW'] = Price_Day.S_DQ_ADJPRECLOSE.values\n",
    "        Weight_new['New_Weight'] = Weight_new['Weight'] * (Weight_new['S_DQ_ADJCLOSE_NEW'] / Weight_new['S_DQ_ADJCLOSE'])\n",
    "        Weight_new['normalized_weight'] = Weight_new['New_Weight'] / Weight_new['New_Weight'].sum()\n",
    "        Weight_new.fillna(0, inplace=True)\n",
    "        \n",
    "        w0 = pd.DataFrame(Weight_new.normalized_weight.values - bmw_Day.Weight.values).T\n",
    "    \n",
    "    # 换手率约束\n",
    "    turn = 100\n",
    "    solver1 = 'glpk'\n",
    "    \n",
    "    # 优化函数，如果在某个换仓日优化问题无解，则这个日期会被存在error_date里，主动权重沿用上一期，有解时error_date是目标函数的最优值，主要用于看无解的日期\n",
    "    a11, error_date = cvxlp2_turn(\n",
    "        Date, MU, bmw, w0, turn, A_leq, b_leq, Aeq, beq, 0.01, solver1)\n",
    "    # print(error_date)\n",
    "    \n",
    "    # 仓位存储\n",
    "    Weight_final = pd.DataFrame({'TRADE_DT': Factor_Day.TRADE_DT,\n",
    "                                 'S_INFO_WINDCODE': Factor_Day.S_INFO_WINDCODE, 'Weight': bmw_Day.Weight + a11, 'S_DQ_ADJCLOSE': Price_Day.S_DQ_ADJCLOSE})\n",
    "    Position_Day = pd.DataFrame(\n",
    "        {'TRADE_DT': bmw_Day.TRADE_DT, 'S_INFO_WINDCODE': bmw_Day.S_INFO_WINDCODE, 'POSITION': bmw_Day.Weight + a11})\n",
    "    Position_list.append(Position_Day)\n",
    "    Error_date_list.append(error_date)\n",
    "    i = i+1\n",
    "    print('换手率差值为'+str(np.sum(abs(pd.DataFrame(a11).T - w0), axis = 1)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position_list = []\n",
    "# Error_date_list = []\n",
    "drop_list = []\n",
    "\n",
    "Industry_list = Industry.IND_CODE.unique().tolist()\n",
    "i = 2\n",
    "# 遍历每一个交易日\n",
    "Date = Factor_all.TRADE_DT.unique()[i+1]\n",
    "Industry_list = Industry.IND_CODE.unique().tolist()\n",
    "Factor_Day = Factor_all[Factor_all['TRADE_DT'] == Date]\n",
    "Factor_Day.index = range(len(Factor_Day))\n",
    "\n",
    "# 在2023年后，存在部分股票的行业不存在于industry，删除这部分股票\n",
    "for index, code in enumerate(Factor_Day['S_INFO_WINDCODE']):\n",
    "    if len(Industry.loc[Industry['S_INFO_WINDCODE'] == code]) == 0:\n",
    "        drop_list.append(code)\n",
    "Factor_Day = Factor_Day[~Factor_Day['S_INFO_WINDCODE'].isin(drop_list)]\n",
    "\n",
    "# 取因子值\n",
    "# MU = Factor_all[Factor_all['TRADE_DT'] == Date]\n",
    "MU = pd.DataFrame(Factor_Day['FACTOR'].values)\n",
    "\n",
    "# 计算行业暴露，构造行业中性约束\n",
    "beq = pd.DataFrame(0, index=range(len(Industry_list)), columns=[0])\n",
    "Aeq = pd.DataFrame(0, index=range(len(Industry_list)),\n",
    "                columns=range(len(Factor_Day)))\n",
    "for index, code in enumerate(Factor_Day['S_INFO_WINDCODE']):\n",
    "    ind = Industry.loc[Industry['S_INFO_WINDCODE']\n",
    "                    == code, 'IND_CODE'].values[0]\n",
    "    Aeq.iloc[Industry_list.index(ind), index] = 1\n",
    "\n",
    "# 计算市值暴露，构造市值中性约束\n",
    "MarketCap_Day = MarketCap[MarketCap['TRADE_DT'] == Date]\n",
    "MarketCap_Day = MarketCap_Day[MarketCap_Day.S_INFO_WINDCODE.isin(\n",
    "    Factor_Day.S_INFO_WINDCODE.tolist())]\n",
    "log_market_value = np.log(MarketCap_Day['S_VAL_MV'])\n",
    "mean = np.sum(log_market_value *\n",
    "            MarketCap_Day['S_VAL_MV']) / np.sum(MarketCap_Day['S_VAL_MV'])\n",
    "\n",
    "std = MarketCap_Day['S_VAL_MV'].std()\n",
    "MarketCap_Day['VALMV_Expose'] = (log_market_value - mean) / std\n",
    "\n",
    "A_leq = pd.concat([pd.DataFrame(MarketCap_Day.VALMV_Expose.to_numpy()).T,\n",
    "                pd.DataFrame(-MarketCap_Day.VALMV_Expose.to_numpy()).T])\n",
    "\n",
    "b_leq = pd.DataFrame([0.5, 0.5])\n",
    "\n",
    "# 取基准指数权重\n",
    "Weight_Day = Weight[Weight['TRADE_DT'] == Date]\n",
    "bmw_Day = pd.DataFrame(\n",
    "    {'TRADE_DT': Factor_Day.TRADE_DT, 'S_INFO_WINDCODE': Factor_Day.S_INFO_WINDCODE, 'Weight': np.zeros(len(Factor_Day))})  # 基准指数权重\n",
    "\n",
    "for code in bmw_Day.S_INFO_WINDCODE:\n",
    "    if code in Weight_Day.S_INFO_WINDCODE.tolist():\n",
    "        bmw_Day.loc[bmw_Day.S_INFO_WINDCODE == code,\n",
    "                    'Weight'] = Weight_Day.loc[Weight_Day.S_INFO_WINDCODE == code, 'ADJ_I_WEIGHT'].values\n",
    "\n",
    "# 初始主动权重为基准指数权重，否则为上一期的主动权重\n",
    "bmw = pd.DataFrame(bmw_Day.Weight.values).T\n",
    "Price_Day = Price[Price['TRADE_DT'] == Date]\n",
    "\n",
    "if i == 0:\n",
    "    w0 = bmw\n",
    "else:\n",
    "    # w0 = pd.DataFrame(a11).T \n",
    "    # 取收盘价，用于计算每一期间权重变化\n",
    "    Price_Day = Price_Day[Price_Day.S_INFO_WINDCODE.isin(Factor_Day.S_INFO_WINDCODE.tolist())]\n",
    "    Price_Day.index = range(len(Price_Day))\n",
    "    Weight_new = Factor_Day.merge(Weight_final, on='S_INFO_WINDCODE',\n",
    "                                how='left')\n",
    "    Weight_new['S_DQ_ADJCLOSE_NEW'] = Price_Day.S_DQ_ADJPRECLOSE.values\n",
    "    Weight_new['New_Weight'] = Weight_new['Weight'] * (Weight_new['S_DQ_ADJCLOSE_NEW'] / Weight_new['S_DQ_ADJCLOSE'])\n",
    "    Weight_new['normalized_weight'] = Weight_new['New_Weight'] / Weight_new['New_Weight'].sum()\n",
    "    Weight_new.fillna(0, inplace=True)\n",
    "    \n",
    "    w0 = pd.DataFrame(Weight_new.normalized_weight.values - bmw_Day.Weight.values).T\n",
    "\n",
    "# 换手率约束\n",
    "turn = 1\n",
    "solver1 = 'glpk'\n",
    "\n",
    "# 优化函数，如果在某个换仓日优化问题无解，则这个日期会被存在error_date里，主动权重沿用上一期，有解时error_date是目标函数的最优值，主要用于看无解的日期\n",
    "a11, error_date = cvxlp2_turn(\n",
    "    Date, MU, bmw, w0, turn, A_leq, b_leq, Aeq, beq, 0.01, solver1)\n",
    "\n",
    "# 记录收盘价用于计算权重\n",
    "Weight_final = pd.DataFrame({'TRADE_DT': Factor_Day.TRADE_DT,\n",
    "                            'S_INFO_WINDCODE': Factor_Day.S_INFO_WINDCODE, 'Weight': bmw_Day.Weight + a11, 'S_DQ_ADJCLOSE': Price_Day.S_DQ_ADJCLOSE})\n",
    "Position_Day = pd.DataFrame(\n",
    "    {'TRADE_DT': bmw_Day.TRADE_DT, 'S_INFO_WINDCODE': bmw_Day.S_INFO_WINDCODE, 'POSITION': bmw_Day.Weight + a11})\n",
    "# print(error_date)\n",
    "Position_Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aeq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = []\n",
    "\n",
    "Industry_list = Industry.IND_CODE.unique().tolist()\n",
    "i = 0\n",
    "# 遍历每一个交易日\n",
    "Date = Factor_all.TRADE_DT.unique()[i+1]\n",
    "Industry_list = Industry.IND_CODE.unique().tolist()\n",
    "Factor_Day = Factor_all[Factor_all['TRADE_DT'] == Date]\n",
    "Factor_Day.index = range(len(Factor_Day))\n",
    "\n",
    "# 在2023年后，存在部分股票的行业不存在于industry，删除这部分股票\n",
    "for index, code in enumerate(Factor_Day['S_INFO_WINDCODE']):\n",
    "    if len(Industry.loc[Industry['S_INFO_WINDCODE'] == code]) == 0:\n",
    "        drop_list.append(code)\n",
    "Factor_Day = Factor_Day[~Factor_Day['S_INFO_WINDCODE'].isin(drop_list)]\n",
    "\n",
    "# 取因子值\n",
    "# MU = Factor_all[Factor_all['TRADE_DT'] == Date]\n",
    "MU = pd.DataFrame(Factor_Day['FACTOR'].values)\n",
    "\n",
    "# 计算行业暴露，构造行业中性约束\n",
    "beq = pd.DataFrame(0, index=range(len(Industry_list)), columns=[0])\n",
    "Aeq = pd.DataFrame(0, index=range(len(Industry_list)),\n",
    "                   columns=range(len(Factor_Day)))\n",
    "for index, code in enumerate(Factor_Day['S_INFO_WINDCODE']):\n",
    "    ind = Industry.loc[Industry['S_INFO_WINDCODE']\n",
    "                       == code, 'IND_CODE'].values[0]\n",
    "    Aeq.iloc[Industry_list.index(ind), index] = 1\n",
    "\n",
    "# 计算市值暴露，构造市值中性约束\n",
    "MarketCap_Day = MarketCap[MarketCap['TRADE_DT'] == Date]\n",
    "MarketCap_Day = MarketCap_Day[MarketCap_Day.S_INFO_WINDCODE.isin(\n",
    "    Factor_Day.S_INFO_WINDCODE.tolist())]\n",
    "log_market_value = np.log(MarketCap_Day['S_VAL_MV'])\n",
    "mean = np.sum(log_market_value *\n",
    "              MarketCap_Day['S_VAL_MV']) / np.sum(MarketCap_Day['S_VAL_MV'])\n",
    "\n",
    "std = MarketCap_Day['S_VAL_MV'].std()\n",
    "MarketCap_Day['VALMV_Expose'] = (log_market_value - mean) / std\n",
    "\n",
    "A_leq = pd.concat([pd.DataFrame(MarketCap_Day.VALMV_Expose.to_numpy()).T,\n",
    "                   pd.DataFrame(-MarketCap_Day.VALMV_Expose.to_numpy()).T])\n",
    "\n",
    "b_leq = pd.DataFrame([0.5, 0.5])\n",
    "\n",
    "# 取基准指数权重\n",
    "Weight_Day = Weight[Weight['TRADE_DT'] == Date]\n",
    "bmw_Day = pd.DataFrame(\n",
    "    {'TRADE_DT': Factor_Day.TRADE_DT, 'S_INFO_WINDCODE': Factor_Day.S_INFO_WINDCODE, 'Weight': np.zeros(len(Factor_Day))})  # 基准指数权重\n",
    "\n",
    "for code in bmw_Day.S_INFO_WINDCODE:\n",
    "    if code in Weight_Day.S_INFO_WINDCODE.tolist():\n",
    "        bmw_Day.loc[bmw_Day.S_INFO_WINDCODE == code,\n",
    "                    'Weight'] = Weight_Day.loc[Weight_Day.S_INFO_WINDCODE == code, 'ADJ_I_WEIGHT'].values\n",
    "\n",
    "# 初始主动权重为基准指数权重，否则为上一期的主动权重\n",
    "bmw = pd.DataFrame(bmw_Day.Weight.values).T\n",
    "\n",
    "if i == 0:\n",
    "    w0 = bmw\n",
    "else:\n",
    "    # w0 = pd.DataFrame(a11).T\n",
    "    # 取收盘价，用于计算每一期间权重变化\n",
    "    Price_Day = Price[Price['TRADE_DT'] == Date]\n",
    "    Price_Day = Price_Day[Price_Day.S_INFO_WINDCODE.isin(\n",
    "        Factor_Day.S_INFO_WINDCODE.tolist())]\n",
    "    Price_Day.index = range(len(Price_Day))\n",
    "    Weight_new = Factor_Day.merge(Weight_final, on='S_INFO_WINDCODE',\n",
    "                                  how='left')\n",
    "    Weight_new['S_DQ_ADJCLOSE_NEW'] = Price_Day.S_DQ_ADJPRECLOSE.values\n",
    "    Weight_new['New_Weight'] = Weight_new['Weight'] * \\\n",
    "        (Weight_new['S_DQ_ADJCLOSE_NEW'] / Weight_new['S_DQ_ADJCLOSE'])\n",
    "    Weight_new['normalized_weight'] = Weight_new['New_Weight'] / \\\n",
    "        Weight_new['New_Weight'].sum()\n",
    "    Weight_new.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weight_new = Factor_Day.merge(Weight_final, on='S_INFO_WINDCODE',\n",
    "                 how='left')\n",
    "Weight_new['S_DQ_ADJCLOSE_NEW'] = Price_Day.S_DQ_ADJPRECLOSE.values\n",
    "Weight_new['New_Weight'] = Weight_new['Weight'] * \\\n",
    "    (Weight_new['S_DQ_ADJCLOSE_NEW'] / Weight_new['S_DQ_ADJCLOSE'])\n",
    "Weight_new['normalized_weight'] = Weight_new['New_Weight'] / \\\n",
    "    Weight_new['New_Weight'].sum()\n",
    "Weight_new.fillna(0, inplace = True)\n",
    "Weight_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight_new['price_change_ratio'] = (\n",
    "#     Weight_new['S_DQ_ADJCLOSE_NEW'] / Weight_new['S_DQ_ADJCLOSE'])\n",
    "\n",
    "# Calculate the new weighted column\n",
    "Weight_new['New_Weight'] = Weight_new['Weight'] * \\\n",
    "     (Weight_new['S_DQ_ADJCLOSE_NEW'] / Weight_new['S_DQ_ADJCLOSE'])\n",
    "\n",
    "# Normalize the new weighted column\n",
    "Weight_new['normalized_weight'] = Weight_new['New_Weight'] / \\\n",
    "    Weight_new['New_Weight'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weight_new.fillna(0, inplace = True)\n",
    "Weight_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 得到优化后权重进行全程和分年度回测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Position = pd.concat(Position_list, ignore_index = True)\n",
    "Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Position = Position[Position.POSITION != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BenchReturn = BenchReturn.loc[BenchReturn.index < max(Position.TRADE_DT)]\n",
    "Price = Price.loc[Price.TRADE_DT < max(Position.TRADE_DT)]\n",
    "Position['date'] = pd.to_datetime(Position['TRADE_DT'], format='%Y%m%d')\n",
    "# 全程回测\n",
    "NetValueTmp, PerformTmp = Back_Testing(\n",
    "    Position, Price, BenchReturn, RiskFreeReturn)\n",
    "NetValueTmp.index = pd.to_datetime(NetValueTmp.index, format='%Y%m%d')\n",
    "grouped = NetValueTmp.groupby(NetValueTmp.index.year)\n",
    "df_list = [(_, group) for _, group in grouped]\n",
    "year_list = [year for year, group in grouped]\n",
    "Perform = pd.DataFrame(columns=['年化收益(%)', '基准年化收益(%)', '超额年化收益(%)',\n",
    "                                '超额年化波动(%)', '信息比率', '超额最大回撤(%)', '胜率(%)', '换手率(年均)'], index=year_list)\n",
    "\n",
    "# 分年度回测\n",
    "for year, group in df_list:\n",
    "    Return = pd.DataFrame(group[['策略净值', '策略收益']])\n",
    "    Return.rename(columns={'策略净值': 'NETVALUE'}, inplace=True)\n",
    "    Return.rename(columns={'策略收益': 'RETURN'}, inplace=True)\n",
    "    Position_year = Position[Position['date'].dt.year == year]\n",
    "\n",
    "    Calender = pd.DataFrame(\n",
    "        {'TRADE_DT': [timestamp.strftime('%Y%m%d') for timestamp in group.index]})\n",
    "    Risk_free_file = 'Input/副本无风险利率.xlsx'  # 无风险利率数据路径\n",
    "    RiskFreeReturn = LoadRiskFreeReturn(Risk_free_file, Calender)  # 加载无风险利率数据\n",
    "    BenchReturn = Load_Return(conn, Calender)\n",
    "\n",
    "    # 换手率\n",
    "    TurnOverRate = Cal_TurnOver(Position_year)\n",
    "    # 无风险收益：\n",
    "    RiskfreeReturn, RiskfreeIntervalRet, RiskfreeIntervaStd, RiskfreeAnnualRet, RiskfreeAnnualStd, RiskfreeMaxdrawdown = PerfStatis(\n",
    "        RiskFreeReturn, frequency='D')\n",
    "\n",
    "    # 基准收益：\n",
    "    # BenchReturn.loc[BenchReturn.index <= PeriodList[0], 'RETURN'] = 0 #这一句是否需要删除，有待验证\n",
    "    BenchReturn, BenchIntervalRet, BenchIntervaStd, BenchAnnualRet, BenchAnnualStd, BenchMaxdrawdown = PerfStatis(\n",
    "        BenchReturn, frequency='D')\n",
    "\n",
    "    # 策略收益：\n",
    "    StrategyReturn, StrategyIntervalRet, StrategyIntervaStd, StrategyAnnualRet, StrategyAnnualStd, StrategyMaxdrawdown = PerfStatis(\n",
    "        Return, frequency='D', if_Returned=False)\n",
    "\n",
    "    # 超额收益：\n",
    "    initial_ExcessReturn = Cal_Excess(StrategyReturn, BenchReturn)\n",
    "    ExcessReturn, ExcessIntervalRet, ExcessIntervaStd, ExcessAnnualRet, ExcessAnnualStd, ExcessMaxdrawdown = PerfStatis(\n",
    "        initial_ExcessReturn, frequency='D', if_Returned=False)\n",
    "\n",
    "    # 胜率：\n",
    "    StrategyWinper = Cal_Winper(ExcessReturn)\n",
    "    # 汇总：\n",
    "    Perform.loc[year, :] = StrategyAnnualRet, BenchAnnualRet, ExcessAnnualRet, ExcessAnnualStd, (\n",
    "        ExcessAnnualRet-RiskfreeAnnualRet)/ExcessAnnualStd, ExcessMaxdrawdown, StrategyWinper, TurnOverRate\n",
    "\n",
    "\n",
    "# 同全程汇总\n",
    "new_row = pd.DataFrame(PerformTmp[['年化收益(%)', '基准年化收益(%)', '超额年化收益(%)',\n",
    "                       '超额年化波动(%)', '信息比率', '超额最大回撤(%)', '胜率(%)', '换手率(年均)']].values, index=['整体'])\n",
    "new_row.columns = Perform.columns\n",
    "Perform = pd.concat([Perform, new_row])\n",
    "Perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NetValueTmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = 'D'\n",
    "PeriodList = Position.TRADE_DT.unique()\n",
    "# 计算策略的日频收益率\n",
    "# bins = np.insert(PeriodList, 0, '00000000')\n",
    "# Price['TRADE_PERIOD'] = pd.cut(\n",
    "#     Price['TRADE_DT'], bins=bins, labels=PeriodList[:])\n",
    "Price['TRADE_PERIOD'] = [\n",
    "    PeriodList[np.where(PeriodList >= i)[0][0]] for i in Price.TRADE_DT]\n",
    "StrategyReturn = pd.DataFrame(Price.groupby(Price.TRADE_PERIOD).apply(\n",
    "    M2D, Position).values, index=Price.TRADE_DT.unique(), columns=['RETURN'])\n",
    "StrategyReturn.fillna(0, inplace=True)\n",
    "NetValue = pd.DataFrame(index=BenchReturn.index,\n",
    "                        columns=['基准净值', '策略净值', '相对净值', '策略收益'])\n",
    "NetValue['策略收益'] = StrategyReturn['RETURN']\n",
    "# 计算换手率\n",
    "TurnOverRate = Cal_TurnOver(Position)\n",
    "# 计算无风险利率（货基指数）的年化收益\n",
    "RiskfreeReturn, RiskfreeIntervalRet, RiskfreeIntervaStd, RiskfreeAnnualRet, RiskfreeAnnualStd, RiskfreeMaxdrawdown = PerfStatis(\n",
    "    RiskFreeReturn, frequency)\n",
    "# 统计策略的净值、区间收益率、区间波动率、年化收益率、年化波动率、夏普比率、最大回撤\n",
    "StrategyReturn, StrategyIntervalRet, StrategyIntervaStd, StrategyAnnualRet, StrategyAnnualStd, StrategyMaxdrawdown = PerfStatis(\n",
    "    StrategyReturn, frequency)\n",
    "# 统计基准的净值、区间收益率、区间波动率、年化收益率、年化波动率、夏普比率、最大回撤\n",
    "BenchReturn.loc[BenchReturn.index <= PeriodList[0], 'RETURN'] = 0\n",
    "BenchReturn, BenchIntervalRet, BenchIntervaStd, BenchAnnualRet, BenchAnnualStd, BenchMaxdrawdown = PerfStatis(\n",
    "    BenchReturn, frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BenchReturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 15))  # 设置图形大小\n",
    "NetValueTmp.index = NetValueTmp.index.strftime('%Y-%m-%d')\n",
    "# 遍历DataFrame的每一列，为每一列绘制一条线，并设置标签为列名\n",
    "for column in NetValueTmp.columns:\n",
    "    plt.plot(NetValueTmp[column], label=column)\n",
    "\n",
    "plt.xlabel('日期')  # 设置x轴标签\n",
    "plt.ylabel('净值')  # 设置y轴标签\n",
    "plt.title('分组超额折线图')  # 设置标题\n",
    "plt.legend(loc='upper left', fontsize='x-large')  # 显示图例\n",
    "\n",
    "x = np.arange(0, len(NetValueTmp.index), 100)  # 每100个数据点显示一个刻度\n",
    "plt.xticks(x, NetValueTmp.index[x], rotation=45)  # 设置x轴刻度标签并旋转45度\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
